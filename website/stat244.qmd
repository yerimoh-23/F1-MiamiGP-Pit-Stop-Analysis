---
title: "STAT-244-SC"
---

```{r setup, include=FALSE}
library(readr)
library(visdat)
library(dplyr)
library(ggplot2)
library(gridExtra) # allows to show multiplot plots on the same page
library(ggmosaic)
library(tidyverse)
library(tidymodels)
library(caret)
```

# Final Project Report

-   May 8, 2025
-   Eonbi Choi, Yerim Oh

# F1 Miami Grand Prix 2024 Pit Stop Analysis

## Abstract
This study employs different regression models to predict when a driver to make a pit stop at during a race, based on the Formula 1 Miami Grand Prix 2024 data. The dataset includes various indicators (32 variables), such as driver details, lap times, pit in/out times, tire information, and track status, for 1111 laps. The aim of this analysis is to estimate pit stop timing based on tire and lap information. The models demonstrate that tire compound, lap number, etc. are significant predictors of pit stop behavior, offering insights into strategic decision-making in race management.

## Datasets

The Formula 1 data used in this study are obtained from the f1dataR R package that accesses Formula 1 data via the FastF1 Python library. The dataset includes lap-by-lap session data from the 2024 Miami Grand Prix and comprise 1111 laps and 32 variables. These variables include driver details, lap times, pit in/out times, tire information, and track status.

**Source**: R Package 'f1dataR'

-   **Description**: <https://cran.r-project.org/web/packages/f1dataR/f1dataR.pdf>

-   **Data sources**: Obtain Formula 1 data via the unofficial API <https://www.formula1.com/en/timing/f1-live> via the 'fastf1' 'Python' library <https://docs.fastf1.dev/>.

-   Last accessed date/time: April 28, 2025 16:51 PM

```{r echo=FALSE}
load("/Users/ohyes323/MHC/STAT-244SC/2024Miami/final_submission/data/lap_dat.Rdata")
head(lap_dat)
```

### Variables

quantitative variable:

-   `lap_time`: recorded time to complete a lap (seconds)

-   `lap_number`: lap number from which the telemetry data was recorded (number of laps)

-   `tyre_life`: number of laps completed on a set of tires (number of laps)

categorical variable:

-   `compound`: type of tire used (SOFT, MEDIUM, HARD)

-   `pit_in`: whether a driver made a pit stop during a lap (binary: 0 = no pit stop, 1 = pit stop occured)

### Clean/Rearrange Data
Rearrange data to consist only the variables we are interested in
```{r echo=FALSE, include=FALSE}
lap_re <- lap_dat %>%
  select(lap_time, lap_number, compound, tyre_life) %>%
  mutate(compound = as.factor(compound),
         pit_in = ifelse(is.nan(lap_dat$pit_in_time), 0, 1))
head(lap_re)
```

#### Check missing values

![](https://raw.githubusercontent.com/yerimoh-23/F1-MiamiGP-Pit-Stop-Analysis/main/website_img/missing_data.png)

Data for `lap_time` are missing 5 values which are less than 0.1% of the entire observation

#### Finalize data we are going to use
```{r echo=FALSE}
# drop missing values
miami2024 <- na.omit(lap_re)
head(miami2024)
```

#### Why certain data points are missing
Out of 5 missing lap time records four records have a track status code of 41. However, no description of this code value is provided in the API. Thus, we assume that either the track was not fully cleared or conditions were not suitable for racing. The other missing record was due to a driver failing to complete a lap due to collision.

## Data Visualization

Our response variable:`pit_in`

![](https://raw.githubusercontent.com/yerimoh-23/F1-MiamiGP-Pit-Stop-Analysis/main/website_img/geompoint.png)

**Number of pit stops for each lap**
![](https://raw.githubusercontent.com/yerimoh-23/F1-MiamiGP-Pit-Stop-Analysis/main/website_img/barplot.png)

**Density plot for lap time of each team**
![](https://raw.githubusercontent.com/yerimoh-23/F1-MiamiGP-Pit-Stop-Analysis/main/website_img/densityplot.png)
- A smaller lap time in Formula 1 means that the driver completed a lap more quickly. In racing, lower lap times are better because they indicate higher performance.

**Box plot of tire life for each compound**
![](https://raw.githubusercontent.com/yerimoh-23/F1-MiamiGP-Pit-Stop-Analysis/main/website_img/boxplot.png)
- The tire compound directly affects tire life, and the relationship is based on a trade-off between performance (speed/grip) and durability. Therefore, the softer the compound, the shorter the tire life.

**Number of tires for each compound**
![](https://raw.githubusercontent.com/yerimoh-23/F1-MiamiGP-Pit-Stop-Analysis/main/website_img/barplot_cpd.png)
- Since the tire life is shorter for the softer compounds, but has a better performance, the drivers preferred MEDIUM tire to balance the trade-off.

# Linear Regression Model

## Research questions

1. Were drivers more likely to make pit stops when their lap time was longer and their tires were older compared to when their lap time was shorter and their tires were less used?
2. Were drivers more likely to make pit stops when their lap times were longer, their tires were older, and considering the type of tires they were using and their progress in the race?

### Linear models considering based on the research question

- **Model 1**:
$$
\mathbb{E}(pit\_in \mid lap\_time,\ tyre\_life) = \beta_0 + \beta_1(lap\_time) + \beta_2(tyre\_life)
$$

- **Model 2**:
$$
\begin{aligned}
\mathbb{E}(pit\_in \mid lap\_time, \ lap\_number, \ compound, \ tyre\_life)  &= \beta_0 + \beta_1(lap\_time) \\ &+ \beta_2(lap\_number) + \beta_3(compound) \\ &+ \beta_4(tyre\_life)
\end{aligned}
$$

```{r}
# STEP 1: Model Specification
lm_spec <- linear_reg() %>%
  set_mode("regression") %>%
  set_engine("lm")

# STEP 2: Model estimation
# first linear model
pit_lm1 <- lm_spec %>%
  fit(pit_in ~ lap_time + tyre_life, data = miami2024)
pit_lm1 %>% tidy()

# second linear model
pit_lm2 <- lm_spec %>%
  fit(pit_in ~ lap_time + lap_number + compound + tyre_life, data = miami2024)
pit_lm2 %>% tidy()
```

## Cross Validation

Cross-validation is a statistical method used to evaluate how well a model performs by splitting the data into multiple subsets to train the model on some subsets and validate it on the remaining subsets.

- **Goal**: Provide a more reliable and unbiased estimate of a model's performance predicting new data, in order to detect overfitting and improve model generalization

### Dividing data into test set and training set

-   **k-fold CV**: We can use k-fold cross-validation to estimate the typical error in our model predictions for new data:

    -   Divide the data into $k$ folds (or groups) of approximately equal size.
    -   Repeat the following procedures for each fold $j = 1,2,...,k$:
        -   Remove fold $j$ from the data set.
        -   Fit a model using the data in the other $k-1$ folds (training).
        -   Use this model to predict the responses for the $n_j$ cases in fold $j$: $\hat{y}_1, ..., \hat{y}_{n_j}$.
        -   Calculate the MAE/MSE for fold $j$ (testing):
    -   Combine this information into one measure of model quality

### Error metric to use

-   Mean absolute error (MAE) of an estimator measures the absolute difference between the predicted values and the actual values in the dataset.

    -   $\text{MAE}_j = \frac{1}{n_j}\sum_{i=1}^{n_j} |y_i - \hat{y}_i|$
    -   $\text{CV}_{(k)} = \frac{1}{k} \sum_{j=1}^k \text{MAE}_j$

-   Mean squared error (MSE) of an estimator measures the average squared difference between the predicted values and the actual values in the dataset.

    -   $\text{MSE}_j = \frac{1}{n_j}\sum_{i=1}^{n_j} (y_i - \hat{y}_i)^2$
    -   $\text{CV}_{(k)} = \frac{1}{k} \sum_{j=1}^k \text{MSE}_j$

#### MAE vs. MSE

The advantage of using MAE is that it's more robust to outliers, giving equal weight to all errors. Thus, it's more suitable when outliers are not a significant concern.

On the other hand, MSE gives more weight to larger errors than smaller ones, making it highly sensitive to outliers. MSE is more suitable when the risk of prediction mistakes is crucial and the goal is to minimize the risk of errors.

Since outliers are less of a concern for us as they don't lead to any life threatening or other major issues, we prioritize models that are directly interpretable. Our data is less common and less familiar to many people, so we decided to choose a model based on MAE.

```{r}
pit_lm1 %>% augment(new_data = miami2024) %>%
  mae(truth = pit_in, estimate = .pred)

pit_lm2 %>% augment(new_data = miami2024) %>%
  mae(truth = pit_in, estimate = .pred)
```

## k-fold CV implementation for different values of k

### k=5

**Model 1**

```{r}
# set seed for reproducibility
set.seed(123)

pit_lm1_k5 = lm_spec %>%
  fit_resamples(
    pit_in ~ lap_time + tyre_life,
    resamples = vfold_cv(miami2024, v = 5),
    metrics = metric_set(mae, rmse)
  )
pit_lm1_k5 %>% collect_metrics()

# get fold-by-fold results
pit_lm1_k5 %>% unnest(.metrics) %>%
  filter(.metric == "mae")
```

-   Based on the random folds above, MAE was best for fold 1 (0.048) and worst for fold 2 (0.056).

**Model 2**

```{r}
# set seed for reproducibility
set.seed(123)

pit_lm2_k5 = lm_spec %>%
  fit_resamples(
    pit_in ~ lap_time + lap_number + compound + tyre_life,
    resamples = vfold_cv(miami2024, v = 5),
    metrics = metric_set(mae, rmse)
  )
pit_lm2_k5 %>% collect_metrics()

# get fold-by-fold results
pit_lm2_k5 %>% unnest(.metrics) %>%
  filter(.metric == "mae")
```

-   Based on the random folds above, MAE was best for fold 1 (0.053) and worst for fold 2 (0.062).

```{r}
# 5-fold CV MAE and sd
pit_lm1_k5 %>% unnest(.metrics) %>%
  filter(.metric == "mae") %>%
  summarize(mean = mean(.estimate), sd = sd(.estimate))

pit_lm2_k5 %>% unnest(.metrics) %>%
  filter(.metric == "mae") %>%
  summarize(mean = mean(.estimate), sd = sd(.estimate))
```

In-sample and 5-fold CV MAE and standard deviation for both models.

+------------+---------------+---------------+--------------+--------------+
| Model      | In-sample MAE | 5-fold CV MAE | In-sample SD | 5-fold CV SD |
+:===========+==============:+==============:+=============:+=============:+
| `model_1`  | 0.05045       | 0.05073       | 0.15247      | 0.00356      |
+------------+---------------+---------------+--------------+--------------+
| `model_2`  | 0.05975       | 0.05922       | 0.15035      | 0.00360      |
+------------+---------------+---------------+--------------+--------------+

: \vspace{10pt}

### k=10

**Model 1**

```{r}
# set seed for reproducibility
set.seed(123)

pit_lm1_cv = lm_spec %>%
  fit_resamples(
    pit_in ~ lap_time + tyre_life,
    resamples = vfold_cv(miami2024, v = 10),
    metrics = metric_set(mae, rmse)
  )
pit_lm1_cv %>% collect_metrics()

# get fold-by-fold results
pit_lm1_cv %>% unnest(.metrics) %>%
  filter(.metric == "mae")
```

-   Based on the random folds above, the MAE was best for fold 1 with an MAE of approximately 0.037 and worst for fold 3 with an MAE of 0.061 approximately.

**Model 2**

```{r}
# set seed for reproducibility
set.seed(123)

pit_lm2_cv = lm_spec %>%
  fit_resamples(
    pit_in ~ lap_time + lap_number + compound + tyre_life,
    resamples = vfold_cv(miami2024, v = 10),
    metrics = metric_set(mae, rmse)
  )
pit_lm2_cv %>% collect_metrics()

# get fold-by-fold results
pit_lm2_cv %>% unnest(.metrics) %>%
  filter(.metric == "mae")
```

-   Based on the random folds above, MAE was best for fold 1 (0.044) and worst for fold 3 (0.070).

```{r}
# 10-fold CV MAE and sd
pit_lm1_cv %>% unnest(.metrics) %>%
  filter(.metric == "mae") %>%
  summarize(mean = mean(.estimate), sd = sd(.estimate))

pit_lm2_cv %>% unnest(.metrics) %>%
  filter(.metric == "mae") %>%
  summarize(mean = mean(.estimate), sd = sd(.estimate))
```

In-sample and 10-fold CV MAE and standard deviation for both models.

+------------+---------------+----------------+--------------+---------------+
| Model      | In-sample MAE | 10-fold CV MAE | In-sample SD | 10-fold CV SD |
+:===========+==============:+===============:+=============:+==============:+
| `model_1`  | 0.05045       | 0.05100        | 0.15247      | 0.00931       |
+------------+---------------+----------------+--------------+---------------+
| `model_2`  | 0.05975       | 0.05939        | 0.15035      | 0.00829       |
+------------+---------------+----------------+--------------+---------------+

: \vspace{10pt}

### k = 20

**Model 1**

```{r}
# set seed for reproducibility
set.seed(123)

pit_lm1_k20 = lm_spec %>%
  fit_resamples(
    pit_in ~ lap_time + tyre_life,
    resamples = vfold_cv(miami2024, v = 20),
    metrics = metric_set(mae, rmse)
  )
pit_lm1_k20 %>% collect_metrics()

# get fold-by-fold results
pit_lm1_k20 %>% unnest(.metrics) %>%
  filter(.metric == "mae")
```

-   Based on the random folds above, MAE was best for fold 10 (0.026) and worst for fold 20 (0.090).

**Model 2**

```{r}
# set seed for reproducibility
set.seed(123)

pit_lm2_k20 = lm_spec %>%
  fit_resamples(
    pit_in ~ lap_time + lap_number + compound + tyre_life,
    resamples = vfold_cv(miami2024, v = 20),
    metrics = metric_set(mae, rmse)
  )
pit_lm2_k20 %>% collect_metrics()

# get fold-by-fold results
pit_lm2_k20 %>% unnest(.metrics) %>%
  filter(.metric == "mae")
```

-   Based on the random folds above, MAE was best for fold 10 (0.032) and worst for fold 20 (0.101).

```{r}
# 20-fold CV MAE and sd
pit_lm1_k20 %>% unnest(.metrics) %>%
  filter(.metric == "mae") %>%
  summarize(mean = mean(.estimate), sd = sd(.estimate))

pit_lm2_k20 %>% unnest(.metrics) %>%
  filter(.metric == "mae") %>%
  summarize(mean = mean(.estimate), sd = sd(.estimate))
```

In-sample and 20-fold CV MAE and standard deviation for both models.

+------------+---------------+----------------+--------------+---------------+
| Model      | In-sample MAE | 20-fold CV MAE | In-sample SD | 20-fold CV SD |
+:===========+==============:+===============:+=============:+==============:+
| `model_1`  | 0.05045       | 0.05086        | 0.15247      | 0.01785       |
+------------+---------------+----------------+--------------+---------------+
| `model_2`  | 0.05975       | 0.05925        | 0.15035      | 0.01781       |
+------------+---------------+----------------+--------------+---------------+

: \vspace{10pt}

### Compare different values of k

+------------+---------------+---------------+----------------+----------------+
| Model      | In-sample MAE | 5-fold CV MAE | 10-fold CV MAE | 20-fold CV MAE |
+:===========+==============:+==============:+===============:+===============:+
| `model_1`  | 0.05045       | 0.05073       | 0.05100        | 0.05086        |
+------------+---------------+---------------+----------------+----------------+
| `model_2`  | 0.05975       | 0.05922       | 0.05939        | 0.05925        |
+------------+---------------+---------------+----------------+----------------+

: \vspace{10pt}

## Final model based on the smallest CV error

All of the above results suggests `model_1` is the better model than `model_2`.

Therefore, our final model based on the smallest CV error is:

$$
\mathbb{E}(pit\_in \mid lap\_time,\ tyre\_life) = \beta_0 + \beta_1(lap\_time) + \beta_2(tyre\_life)
$$

# Logistic Regression Model

## Variables of interest

### Predictors

1.  `lap_time`: recorded time to complete a lap (seconds)
2.  `lap_number`: lap number from which the telemetry data was recorded (number of laps)
3.  `tyre_life`: number of laps completed on a set of tires (number of laps)
4.  `compound`: type of tire used (SOFT, MEDIUM, HARD)

### Response variable

-   `pit_in`: whether a driver made a pit stop during a lap (binary: 0 = no pit stop, 1 = pit stop occurred)

    \begin{align*}
    Y_i &= \begin{cases} 1 & \text{ if a driver pitted on a lap } \\ 0 & \text{ otherwise (i.e., the driver did not pit on lap)} \end{cases}
    \end{align*}

## Our logistic regression model

We are interested in determining the probability of making a pit stop during the 2024 Miami Grand Prix, considering factors such as lap time, track progress, tire age, and the type of tire used.

$$
\begin{aligned} 
\log(odds(pit\_in \mid lap\_time, \ lap\_number, \ tyre\_life, \ compound)) &= \beta_0 + \beta_1 (lap\_time) \\ &+ \beta_2(lap\_number) + \beta_3 (tyre\_life) \\ &+ \beta_4 \ I(compound = MEDIUM) \\ &+ \beta_5 \ I(compound = SOFT)
\end{aligned}
$$

```{r}
# factor `pit_in` for logistic regression analysis
miami2024_glm <- miami2024 %>%
  mutate(pit_in_fac = as.factor(pit_in))
```

```{r}
# logistic regression model
logistic_fit <- train(
  form   = pit_in_fac ~ lap_time + lap_number + tyre_life + compound,
  data   = miami2024_glm,
  family = "binomial", # this is an argument to glm; response is 0 or 1, binomial
  method = "glm",      # method for fit; "generalized linear model"
  trControl = trainControl(method = "none")
)

summary(logistic_fit$finalModel)
```

### Interpretation of exponentiated $\hat{\beta}$ coefficients

```{r}
exp(logistic_fit$finalModel$coefficients)
```

-   $\exp(\beta_0)$: The odds of a driver making a pit stop during a lap, when lap time is 0 seconds, lap number is 0, 0 laps have been completed on the current set of tires, and the HARD compound is, is approximately $9.4088 \times 10^{-9}$.

-   $\exp(\beta_1)$: For every of 1 second increase in lap time, the odds of a driver pitting increase by a factor of 1.1473.

-   $\exp(\beta_2)$: For every additional lap (i.e., increase of 1 in the lap number), we expect the odds of a driver pitting to increase by a factor of 0.8521.

-   $\exp(\beta_3)$: For each additional lap completed on the current set of tires, the odds of a driver pitting increase by a factor of 1.3166.

-   $\exp(\beta_4)$: When using MEDIUM compound tires instead of HARD, the odds of a driver pitting increase by a factor of 1.6404, holding all other variables constant.

-   $\exp(\beta_5)$: When using SOFT compound tires instead of HARD, we expect the odds of a driver pitting to increase by a factor of 6.4324, holding all other variables constant.

#### Mathematically derive $\exp(\beta_1)$

$$
\begin{aligned}
&\log(odds(pit\_in \mid lap\_time = a)) = -18.4816 + 0.1374a
\\
\\ 
&\log(odds(pit\_in \mid lap\_time = a+1)) = -18.4816 + 0.1374(a+1)
\end{aligned}
$$

$$
\begin{aligned}
& \log\left( \frac{odds(pit\_in \mid lap\_time = a+1)}{odds(pit\_in \mid lap\_time = a)} \right)\\
&= \log(odds(pit\_in \mid lap\_time = a+1)) - \log(odds(pit\_in \mid lap\_time = a)) \\
&= (-18.4816 + 0.1374(a+1)) - (-18.4816 + 0.1374) \\
&= 0.1374  \\
&= \hat{\beta_1}
\end{aligned}
$$

Therefore, $\exp(\beta_1) = e^{0.1374} = 1.1473$

### Predicting High Probability of a Pit Stop

To predict a probability of a driver making a pit stop that is very close to 1, we need to input extreme values for the predictors. Based on the five-number summary of our data, we use the following scenario: a lap time of 148.74 seconds, lap number 57, SOFT compound, and a tire age of 45 laps.

```{r}
# miami2024_glm %>% 
#   ggplot(aes(x=lap_time)) +
#     geom_density(fill="#69b3a2", color="#e9ecef", alpha=0.8)

summary(miami2024_glm)
```

```{r}
log_prid_fst <- predict(logistic_fit$finalModel,
            newdata = data.frame(lap_time = 148.74,
                                 lap_number = 57,
                                 tyre_life = 45,
                                 compoundMEDIUM = 0,
                                 compoundSOFT = 1),
            type = "response")
    
odds_pitting_fst = exp(log_prid_fst)
(prob_pitting_fst = odds_pitting_fst/(1+odds_pitting_fst))
```

Using our logistic regression model, we estimate the probability of a pit stop under these conditions to be approximately 0.731. This indicates a high likelihood of a pit stop given these extreme race conditions.

### Predicting Pit Stops with our Logistic Regression Model

-   Estimate the probability of a driver making a pit stop on a lap with the following conditions: 96.00 seconds lap time, 28th lap, 14.78 laps completed on a set of HARD tires.

    ```{r}
    log_prid_hard <- predict(logistic_fit$finalModel,
            newdata = data.frame(lap_time = 96,
                                 lap_number = 28,
                                 tyre_life = 14.78,
                                 compoundMEDIUM = 0,
                                 compoundSOFT = 0),
            type = "response")

    odds_pitting_hard = exp(log_prid_hard)
    (prob_pitting_hard = odds_pitting_hard/(1+odds_pitting_hard))
    ```

There is approximately a 50.08% probability that a driver will make a pit stop on this lap when using HARD tires, holding all other variables constant.

<!-- -->

-   Estimate the probability of a driver making a pit stop on a lap under the same conditions as above but using a set of MEDIUM tires.

    ```{r}
    log_prid_med <- predict(logistic_fit$finalModel,
            newdata = data.frame(lap_time = 96,
                                 lap_number = 28,
                                 tyre_life = 14.78,
                                 compoundMEDIUM = 1,
                                 compoundSOFT = 0),
            type = "response")

    odds_pitting_med = exp(log_prid_med)
    (prob_pitting_med = odds_pitting_med/(1+odds_pitting_med))
    ```

With MEDIUM tires, the probability of making a pit stop increases to 50.14%.

<!-- -->

-   Estimate the probability of a driver making a pit stop on a lap under the same conditions as above but using a set of SOFT tires.

    ```{r}
    log_prid_soft <- predict(logistic_fit$finalModel,
            newdata = data.frame(lap_time = 96,
                                 lap_number = 28,
                                 tyre_life = 14.78,
                                 compoundMEDIUM = 0,
                                 compoundSOFT = 1),
            type = "response")

    odds_pitting_soft = exp(log_prid_soft)
    (prob_pitting_soft = odds_pitting_soft/(1+odds_pitting_soft))
    ```

With SOFT tires, the probability increases slightly to 50.52%.

While all the other variables stay the same, we predict that the probability a driver to made a pit stop is higher if the driver is on a set of SOFT tires compared to other compounds.

## Pros/Cons of logistic regression vs. regular linear regression

### Logistic Regression

+-----------+-------------------------------------------------------------------------------------------------------------------+
| **Pros**  | Since logistic regression is based on a Bernoulli/binomial likelihood, it is a natural model for binary outcomes. |
|           |                                                                                                                   |
|           | Coefficients are interpretable in terms of odds ratios (with log-odds as the linear predictor).                   |
+-----------+-------------------------------------------------------------------------------------------------------------------+
| **Cons**  | The relationship between predictors and the probability is not linear.                                            |
+-----------+-------------------------------------------------------------------------------------------------------------------+

### Linear Regression

+-------------+--------------------------------------------------------------------------+
| **Pros**    | Straightforward linear regression                                        |
|             |                                                                          |
|             | Easy to interpret the coefficients                                       |
+-------------+--------------------------------------------------------------------------+
| **Cons**    | Cannot gaurantee that the predicted probabilities to be between 0 and 1. |
+-------------+--------------------------------------------------------------------------+


